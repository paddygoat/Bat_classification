{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tegwyn/models.py:278: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 16:21:51.696590 547880419344 deprecation.py:506] From /home/tegwyn/models.py:278: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 16:21:51.893388 547880419344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training from step: 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:21:53.859277 547880419344 <ipython-input-1-b083ed8d9149>:198] Training from step: 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 9.6%, cross entropy 2.985335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:04.426807 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #1: rate 0.001000, accuracy 9.6%, cross entropy 2.985335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #2: rate 0.001000, accuracy 12.1%, cross entropy 2.578063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:09.517598 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #2: rate 0.001000, accuracy 12.1%, cross entropy 2.578063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #3: rate 0.001000, accuracy 18.5%, cross entropy 2.591051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:14.530873 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #3: rate 0.001000, accuracy 18.5%, cross entropy 2.591051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #4: rate 0.001000, accuracy 12.1%, cross entropy 2.560455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:19.296164 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #4: rate 0.001000, accuracy 12.1%, cross entropy 2.560455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #5: rate 0.001000, accuracy 19.7%, cross entropy 2.383766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:24.511331 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #5: rate 0.001000, accuracy 19.7%, cross entropy 2.383766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #6: rate 0.001000, accuracy 14.6%, cross entropy 2.583647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:29.203318 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #6: rate 0.001000, accuracy 14.6%, cross entropy 2.583647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #7: rate 0.001000, accuracy 12.7%, cross entropy 2.567971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:34.456909 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #7: rate 0.001000, accuracy 12.7%, cross entropy 2.567971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #8: rate 0.001000, accuracy 19.1%, cross entropy 2.383396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:39.579142 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #8: rate 0.001000, accuracy 19.1%, cross entropy 2.383396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #9: rate 0.001000, accuracy 12.7%, cross entropy 2.484849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:44.118625 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #9: rate 0.001000, accuracy 12.7%, cross entropy 2.484849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #10: rate 0.001000, accuracy 18.5%, cross entropy 2.316376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:48.977061 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #10: rate 0.001000, accuracy 18.5%, cross entropy 2.316376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #11: rate 0.001000, accuracy 15.9%, cross entropy 2.452544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:53.562683 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #11: rate 0.001000, accuracy 15.9%, cross entropy 2.452544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #12: rate 0.001000, accuracy 12.7%, cross entropy 2.354143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:22:58.488838 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #12: rate 0.001000, accuracy 12.7%, cross entropy 2.354143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #13: rate 0.001000, accuracy 14.6%, cross entropy 2.358226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:03.785169 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #13: rate 0.001000, accuracy 14.6%, cross entropy 2.358226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #14: rate 0.001000, accuracy 17.2%, cross entropy 2.339018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:08.832573 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #14: rate 0.001000, accuracy 17.2%, cross entropy 2.339018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #15: rate 0.001000, accuracy 15.9%, cross entropy 2.373358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:13.685711 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #15: rate 0.001000, accuracy 15.9%, cross entropy 2.373358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #16: rate 0.001000, accuracy 13.4%, cross entropy 2.412488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:18.465644 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #16: rate 0.001000, accuracy 13.4%, cross entropy 2.412488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #17: rate 0.001000, accuracy 8.9%, cross entropy 2.289443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:23.615969 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #17: rate 0.001000, accuracy 8.9%, cross entropy 2.289443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #18: rate 0.001000, accuracy 18.5%, cross entropy 2.299155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0911 16:23:28.656935 547880419344 <ipython-input-1-b083ed8d9149>:243] Step #18: rate 0.001000, accuracy 18.5%, cross entropy 2.299155\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "r\"\"\"Simple speech recognition to spot a limited number of keywords.\n",
    "\n",
    "This is a self-contained example script that will train a very basic audio\n",
    "recognition model in TensorFlow. It downloads the necessary training data and\n",
    "runs with reasonable defaults to train within a few hours even only using a CPU.\n",
    "For more information, please see\n",
    "https://www.tensorflow.org/tutorials/audio_recognition.\n",
    "\n",
    "It is intended as an introduction to using neural networks for audio\n",
    "recognition, and is not a full speech recognition system. For more advanced\n",
    "speech systems, I recommend looking into Kaldi. This network uses a keyword\n",
    "detection style to spot discrete words from a small vocabulary, consisting of\n",
    "\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", and \"go\".\n",
    "\n",
    "To run the training process, use:\n",
    "\n",
    "bazel run tensorflow/examples/speech_commands:train\n",
    "\n",
    "This will write out checkpoints to /tmp/speech_commands_train/, and will\n",
    "download over 1GB of open source training data, so you'll need enough free space\n",
    "and a good internet connection. The default data is a collection of thousands of\n",
    "one-second .wav files, each containing one spoken word. This data set is\n",
    "collected from https://aiyprojects.withgoogle.com/open_speech_recording, please\n",
    "consider contributing to help improve this and other models!\n",
    "\n",
    "As training progresses, it will print out its accuracy metrics, which should\n",
    "rise above 90% by the end. Once it's complete, you can run the freeze script to\n",
    "get a binary GraphDef that you can easily deploy on mobile applications.\n",
    "\n",
    "If you want to train on your own data, you'll need to create .wavs with your\n",
    "recordings, all at a consistent length, and then arrange them into subfolders\n",
    "organized by label. For example, here's a possible file structure:\n",
    "\n",
    "my_wavs >\n",
    "  up >\n",
    "    audio_0.wav\n",
    "    audio_1.wav\n",
    "  down >\n",
    "    audio_2.wav\n",
    "    audio_3.wav\n",
    "  other>\n",
    "    audio_4.wav\n",
    "    audio_5.wav\n",
    "\n",
    "You'll also need to tell the script what labels to look for, using the\n",
    "`--wanted_words` argument. In this case, 'up,down' might be what you want, and\n",
    "the audio in the 'other' folder would be used to train an 'unknown' category.\n",
    "\n",
    "To pull this all together, you'd run:\n",
    "\n",
    "bazel run tensorflow/examples/speech_commands:train -- \\\n",
    "--data_dir=my_wavs --wanted_words=up,down\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data\n",
    "#from home.pi.tensorflow.tensorflow_master.tensorflow.examples.speech_commands import input_data\n",
    "#/home/pi/tensorflow/tensorflow_master/tensorflow/examples/speech_commands\n",
    "\n",
    "import models\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  # Set the verbosity based on flags (default is INFO, so we see all messages)\n",
    "  tf.compat.v1.logging.set_verbosity(FLAGS.verbosity)\n",
    "\n",
    "  # Start a new TensorFlow session.\n",
    "  sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "  # Begin by making sure we have the training data we need. If you already have\n",
    "  # training data of your own, use `--data_url= ` on the command line to avoid\n",
    "  # downloading.\n",
    "  model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.feature_bin_count, FLAGS.preprocess)\n",
    "  audio_processor = input_data.AudioProcessor(\n",
    "      FLAGS.data_url, FLAGS.data_dir,\n",
    "      FLAGS.silence_percentage, FLAGS.unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings, FLAGS.summaries_dir)\n",
    "  fingerprint_size = model_settings['fingerprint_size']\n",
    "  label_count = model_settings['label_count']\n",
    "  time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "  # Figure out the learning rates for each training phase. Since it's often\n",
    "  # effective to have high learning rates at the start of training, followed by\n",
    "  # lower levels towards the end, the number of steps and learning rates can be\n",
    "  # specified as comma-separated lists to define the rate at each stage. For\n",
    "  # example --how_many_training_steps=10000,3000 --learning_rate=0.001,0.0001\n",
    "  # will run 13,000 training loops in total, with a rate of 0.001 for the first\n",
    "  # 10,000, and 0.0001 for the final 3,000.\n",
    "  training_steps_list = list(map(int, FLAGS.how_many_training_steps.split(',')))\n",
    "  learning_rates_list = list(map(float, FLAGS.learning_rate.split(',')))\n",
    "  if len(training_steps_list) != len(learning_rates_list):\n",
    "    raise Exception(\n",
    "        '--how_many_training_steps and --learning_rate must be equal length '\n",
    "        'lists, but are %d and %d long instead' % (len(training_steps_list),\n",
    "                                                   len(learning_rates_list)))\n",
    "\n",
    "  input_placeholder = tf.compat.v1.placeholder(\n",
    "      tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "  if FLAGS.quantize:\n",
    "    fingerprint_min, fingerprint_max = input_data.get_features_range(\n",
    "        model_settings)\n",
    "    fingerprint_input = tf.quantization.fake_quant_with_min_max_args(\n",
    "        input_placeholder, fingerprint_min, fingerprint_max)\n",
    "  else:\n",
    "    fingerprint_input = input_placeholder\n",
    "\n",
    "  logits, dropout_prob = models.create_model(\n",
    "      fingerprint_input,\n",
    "      model_settings,\n",
    "      FLAGS.model_architecture,\n",
    "      is_training=True)\n",
    "\n",
    "  # Define loss and optimizer\n",
    "  ground_truth_input = tf.compat.v1.placeholder(\n",
    "      tf.int64, [None], name='groundtruth_input')\n",
    "\n",
    "  # Optionally we can add runtime checks to spot when NaNs or other symptoms of\n",
    "  # numerical errors start occurring during training.\n",
    "  control_dependencies = []\n",
    "  if FLAGS.check_nans:\n",
    "    checks = tf.compat.v1.add_check_numerics_ops()\n",
    "    control_dependencies = [checks]\n",
    "\n",
    "  # Create the back propagation and training evaluation machinery in the graph.\n",
    "  with tf.compat.v1.name_scope('cross_entropy'):\n",
    "    cross_entropy_mean = tf.compat.v1.losses.sparse_softmax_cross_entropy(\n",
    "        labels=ground_truth_input, logits=logits)\n",
    "  if FLAGS.quantize:\n",
    "    tf.contrib.quantize.create_training_graph(quant_delay=0)\n",
    "  with tf.compat.v1.name_scope('train'), tf.control_dependencies(\n",
    "      control_dependencies):\n",
    "    learning_rate_input = tf.compat.v1.placeholder(\n",
    "        tf.float32, [], name='learning_rate_input')\n",
    "    train_step = tf.compat.v1.train.GradientDescentOptimizer(\n",
    "        learning_rate_input).minimize(cross_entropy_mean)\n",
    "  predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "  correct_prediction = tf.equal(predicted_indices, ground_truth_input)\n",
    "  confusion_matrix = tf.math.confusion_matrix(labels=ground_truth_input,\n",
    "                                              predictions=predicted_indices,\n",
    "                                              num_classes=label_count)\n",
    "  evaluation_step = tf.reduce_mean(input_tensor=tf.cast(correct_prediction,\n",
    "                                                        tf.float32))\n",
    "  with tf.compat.v1.get_default_graph().name_scope('eval'):\n",
    "    tf.compat.v1.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "    tf.compat.v1.summary.scalar('accuracy', evaluation_step)\n",
    "\n",
    "  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "  increment_global_step = tf.compat.v1.assign(global_step, global_step + 1)\n",
    "\n",
    "  saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables())\n",
    "\n",
    "  # Merge all the summaries and write them out to /tmp/retrain_logs (by default)\n",
    "  merged_summaries = tf.compat.v1.summary.merge_all(scope='eval')\n",
    "  train_writer = tf.compat.v1.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                                 sess.graph)\n",
    "  validation_writer = tf.compat.v1.summary.FileWriter(\n",
    "      FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "  tf.compat.v1.global_variables_initializer().run()\n",
    "\n",
    "  start_step = 1\n",
    "\n",
    "  if FLAGS.start_checkpoint:\n",
    "    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\n",
    "    start_step = global_step.eval(session=sess)\n",
    "\n",
    "  tf.compat.v1.logging.info('Training from step: %d ', start_step)\n",
    "\n",
    "  # Save graph.pbtxt.\n",
    "  tf.io.write_graph(sess.graph_def, FLAGS.train_dir,\n",
    "                    FLAGS.model_architecture + '.pbtxt')\n",
    "\n",
    "  # Save list of words.\n",
    "  with gfile.GFile(\n",
    "      os.path.join(FLAGS.train_dir, FLAGS.model_architecture + '_labels.txt'),\n",
    "      'w') as f:\n",
    "    f.write('\\n'.join(audio_processor.words_list))\n",
    "\n",
    "  # Training loop.\n",
    "  training_steps_max = np.sum(training_steps_list)\n",
    "  for training_step in xrange(start_step, training_steps_max + 1):\n",
    "    # Figure out what the current learning rate is.\n",
    "    training_steps_sum = 0\n",
    "    for i in range(len(training_steps_list)):\n",
    "      training_steps_sum += training_steps_list[i]\n",
    "      if training_step <= training_steps_sum:\n",
    "        learning_rate_value = learning_rates_list[i]\n",
    "        break\n",
    "    # Pull the audio samples we'll use for training.\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, 0, model_settings, FLAGS.background_frequency,\n",
    "        FLAGS.background_volume, time_shift_samples, 'training', sess)\n",
    "    # Run the graph with this batch of training data.\n",
    "    train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run(\n",
    "        [\n",
    "            merged_summaries,\n",
    "            evaluation_step,\n",
    "            cross_entropy_mean,\n",
    "            train_step,\n",
    "            increment_global_step,\n",
    "        ],\n",
    "        feed_dict={\n",
    "            fingerprint_input: train_fingerprints,\n",
    "            ground_truth_input: train_ground_truth,\n",
    "            learning_rate_input: learning_rate_value,\n",
    "            dropout_prob: 0.5\n",
    "        })\n",
    "    train_writer.add_summary(train_summary, training_step)\n",
    "    tf.compat.v1.logging.info(\n",
    "        'Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
    "        (training_step, learning_rate_value, train_accuracy * 100,\n",
    "         cross_entropy_value))\n",
    "    is_last_step = (training_step == training_steps_max)\n",
    "    if (training_step % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "      set_size = audio_processor.set_size('validation')\n",
    "      total_accuracy = 0\n",
    "      total_conf_matrix = None\n",
    "      for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "        validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(FLAGS.batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy, conf_matrix = sess.run(\n",
    "            [merged_summaries, evaluation_step, confusion_matrix],\n",
    "            feed_dict={\n",
    "                fingerprint_input: validation_fingerprints,\n",
    "                ground_truth_input: validation_ground_truth,\n",
    "                dropout_prob: 1.0\n",
    "            })\n",
    "        validation_writer.add_summary(validation_summary, training_step)\n",
    "        batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "        total_accuracy += (validation_accuracy * batch_size) / set_size\n",
    "        if total_conf_matrix is None:\n",
    "          total_conf_matrix = conf_matrix\n",
    "        else:\n",
    "          total_conf_matrix += conf_matrix\n",
    "      tf.compat.v1.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "      tf.compat.v1.logging.info('Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                                (training_step, total_accuracy * 100, set_size))\n",
    "\n",
    "    # Save the model checkpoint periodically.\n",
    "    if (training_step % FLAGS.save_step_interval == 0 or\n",
    "        training_step == training_steps_max):\n",
    "      checkpoint_path = os.path.join(FLAGS.train_dir,\n",
    "                                     FLAGS.model_architecture + '.ckpt')\n",
    "      tf.compat.v1.logging.info('Saving to \"%s-%d\"', checkpoint_path,\n",
    "                                training_step)\n",
    "      saver.save(sess, checkpoint_path, global_step=training_step)\n",
    "\n",
    "  set_size = audio_processor.set_size('testing')\n",
    "  tf.compat.v1.logging.info('set_size=%d', set_size)\n",
    "  total_accuracy = 0\n",
    "  total_conf_matrix = None\n",
    "  for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "    test_fingerprints, test_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, i, model_settings, 0.0, 0.0, 0, 'testing', sess)\n",
    "    test_accuracy, conf_matrix = sess.run(\n",
    "        [evaluation_step, confusion_matrix],\n",
    "        feed_dict={\n",
    "            fingerprint_input: test_fingerprints,\n",
    "            ground_truth_input: test_ground_truth,\n",
    "            dropout_prob: 1.0\n",
    "        })\n",
    "    batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "    total_accuracy += (test_accuracy * batch_size) / set_size\n",
    "    if total_conf_matrix is None:\n",
    "      total_conf_matrix = conf_matrix\n",
    "    else:\n",
    "      total_conf_matrix += conf_matrix\n",
    "  tf.compat.v1.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "  tf.compat.v1.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                            (total_accuracy * 100, set_size))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--data_url',\n",
    "      type=str,\n",
    "      # pylint: disable=line-too-long\n",
    "      default='https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz',\n",
    "      # pylint: enable=line-too-long\n",
    "      help='Location of speech training data archive on the web.')\n",
    "  parser.add_argument(\n",
    "      '--data_dir',\n",
    "      type=str,\n",
    "###############################################################################################################\n",
    "      default='/media/tegwyn/Xavier_SD/Bat_Detecter/data_for_training_run/',\n",
    "###############################################################################################################\n",
    "      help=\"\"\"\\\n",
    "      Where to download the speech training data to.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--background_volume',\n",
    "      type=float,\n",
    "      default=0.1,\n",
    "      help=\"\"\"\\\n",
    "      How loud the background noise should be, between 0 and 1.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--background_frequency',\n",
    "      type=float,\n",
    "      default=0.8,\n",
    "      help=\"\"\"\\\n",
    "      How many of the training samples have background noise mixed in.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--silence_percentage',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help=\"\"\"\\\n",
    "      How much of the training data should be silence.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--unknown_percentage',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help=\"\"\"\\\n",
    "      How much of the training data should be unknown words.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--time_shift_ms',\n",
    "      type=float,\n",
    "      default=100.0,\n",
    "      help=\"\"\"\\\n",
    "      Range to randomly shift the training audio by in time.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--testing_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of wavs to use as a test set.')\n",
    "  parser.add_argument(\n",
    "      '--validation_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of wavs to use as a validation set.')\n",
    "  parser.add_argument(\n",
    "      '--sample_rate',\n",
    "      type=int,\n",
    "##############################################################################\n",
    "      default=250000,\n",
    "##############################################################################\n",
    "      help='Expected sample rate of the wavs',)\n",
    "  parser.add_argument(\n",
    "      '--clip_duration_ms',\n",
    "      type=int,\n",
    "      #default=1000,\n",
    "      default=1000,\n",
    "      help='Expected duration in milliseconds of the wavs',)\n",
    "  parser.add_argument(\n",
    "      '--window_size_ms',\n",
    "      type=float,\n",
    "      default=30.0,\n",
    "      help='How long each spectrogram timeslice is.',)\n",
    "  parser.add_argument(\n",
    "      '--window_stride_ms',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help='How far to move in time between spectogram timeslices.',)\n",
    "  parser.add_argument(\n",
    "      '--feature_bin_count',\n",
    "      type=int,\n",
    "      default=40,\n",
    "      help='How many bins to use for the MFCC fingerprint',\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--how_many_training_steps',\n",
    "      type=str,\n",
    "      default='15000,3000',\n",
    "      help='How many training loops to run',)\n",
    "  parser.add_argument(\n",
    "      '--eval_step_interval',\n",
    "      type=int,\n",
    "      default=400,\n",
    "      help='How often to evaluate the training results.')\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      type=str,\n",
    "      default='0.001,0.0001',\n",
    "      help='How large a learning rate to use when training.')\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type=int,\n",
    "      default=200,\n",
    "      help='How many items to train with at once',)\n",
    "  parser.add_argument(\n",
    "      '--summaries_dir',\n",
    "      type=str,\n",
    "##############################################################################################################\n",
    "      default='/media/tegwyn/Xavier_SD/Bat_Detecter/data_for_training_run/retrain_logs',\n",
    "##############################################################################################################\n",
    "      help='Where to save summary logs for TensorBoard.')\n",
    "  parser.add_argument(\n",
    "      '--wanted_words',\n",
    "      type=str,\n",
    "###############################################################################################################\n",
    "      #default='yes,no,up,down,left,right,on,off,stop,go',\n",
    "      #default='backward,bed,bird,cat,dog,down,eight,five,follow',\n",
    "      #default='backward,bed,bird,cat,dog,down,eight,five,follow',\n",
    "      default='paa,nna,nnb,nnc,nnd,nne,ppa,ppb,ppc',\n",
    "###############################################################################################################\n",
    "      help='Words to use (others will be added to an unknown label)',)\n",
    "  parser.add_argument(\n",
    "      '--train_dir',\n",
    "      type=str,\n",
    "      default='/tmp/speech_commands_train',\n",
    "      help='Directory to write event logs and checkpoint.')\n",
    "  parser.add_argument(\n",
    "      '--save_step_interval',\n",
    "      type=int,\n",
    "      default=100,\n",
    "      help='Save model checkpoint every save_steps.')\n",
    "  parser.add_argument(\n",
    "      '--start_checkpoint',\n",
    "      type=str,\n",
    "      default='',\n",
    "      help='If specified, restore this pretrained model before any training.')\n",
    "  parser.add_argument(\n",
    "      '--model_architecture',\n",
    "      type=str,\n",
    "      default='conv',\n",
    "      help='What model architecture to use')\n",
    "  parser.add_argument(\n",
    "      '--check_nans',\n",
    "      type=bool,\n",
    "      default=False,\n",
    "      help='Whether to check for invalid numbers during processing')\n",
    "  parser.add_argument(\n",
    "      '--quantize',\n",
    "      type=bool,\n",
    "      default=False,\n",
    "      help='Whether to train the model for eight-bit deployment')\n",
    "  parser.add_argument(\n",
    "      '--preprocess',\n",
    "      type=str,\n",
    "      default='mfcc',\n",
    "      help='Spectrogram processing mode. Can be \"mfcc\", \"average\", or \"micro\"')\n",
    "\n",
    "  # Function used to parse --verbosity argument\n",
    "  def verbosity_arg(value):\n",
    "    \"\"\"Parses verbosity argument.\n",
    "\n",
    "    Args:\n",
    "      value: A member of tf.logging.\n",
    "    Raises:\n",
    "      ArgumentTypeError: Not an expected value.\n",
    "    \"\"\"\n",
    "    value = value.upper()\n",
    "    if value == 'INFO':\n",
    "      return tf.compat.v1.logging.INFO\n",
    "    elif value == 'DEBUG':\n",
    "      return tf.compat.v1.logging.DEBUG\n",
    "    elif value == 'ERROR':\n",
    "      return tf.compat.v1.logging.ERROR\n",
    "    elif value == 'FATAL':\n",
    "      return tf.compat.v1.logging.FATAL\n",
    "    elif value == 'WARN':\n",
    "      return tf.compat.v1.logging.WARN\n",
    "    else:\n",
    "      raise argparse.ArgumentTypeError('Not an expected value')\n",
    "  parser.add_argument(\n",
    "      '--verbosity',\n",
    "      type=verbosity_arg,\n",
    "      default=tf.compat.v1.logging.INFO,\n",
    "      help='Log verbosity. Can be \"INFO\", \"DEBUG\", \"ERROR\", \"FATAL\", or \"WARN\"')\n",
    "\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
