{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tegwyn/models.py:278: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0910 08:15:38.123254 547493154832 deprecation.py:506] From /home/tegwyn/models.py:278: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0910 08:15:38.313199 547493154832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training from step: 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0910 08:15:40.139033 547493154832 <ipython-input-1-b441beb7d664>:198] Training from step: 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 7.5%, cross entropy 2.564805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0910 08:15:47.912714 547493154832 <ipython-input-1-b441beb7d664>:243] Step #1: rate 0.001000, accuracy 7.5%, cross entropy 2.564805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #2: rate 0.001000, accuracy 6.0%, cross entropy 2.632842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0910 08:15:49.540975 547493154832 <ipython-input-1-b441beb7d664>:243] Step #2: rate 0.001000, accuracy 6.0%, cross entropy 2.632842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #3: rate 0.001000, accuracy 8.0%, cross entropy 2.541779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0910 08:15:51.202543 547493154832 <ipython-input-1-b441beb7d664>:243] Step #3: rate 0.001000, accuracy 8.0%, cross entropy 2.541779\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b441beb7d664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m   \u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b441beb7d664>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mground_truth_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_ground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mlearning_rate_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mdropout_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         })\n\u001b[1;32m    239\u001b[0m     \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "r\"\"\"Simple speech recognition to spot a limited number of keywords.\n",
    "\n",
    "This is a self-contained example script that will train a very basic audio\n",
    "recognition model in TensorFlow. It downloads the necessary training data and\n",
    "runs with reasonable defaults to train within a few hours even only using a CPU.\n",
    "For more information, please see\n",
    "https://www.tensorflow.org/tutorials/audio_recognition.\n",
    "\n",
    "It is intended as an introduction to using neural networks for audio\n",
    "recognition, and is not a full speech recognition system. For more advanced\n",
    "speech systems, I recommend looking into Kaldi. This network uses a keyword\n",
    "detection style to spot discrete words from a small vocabulary, consisting of\n",
    "\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", and \"go\".\n",
    "\n",
    "To run the training process, use:\n",
    "\n",
    "bazel run tensorflow/examples/speech_commands:train\n",
    "\n",
    "This will write out checkpoints to /tmp/speech_commands_train/, and will\n",
    "download over 1GB of open source training data, so you'll need enough free space\n",
    "and a good internet connection. The default data is a collection of thousands of\n",
    "one-second .wav files, each containing one spoken word. This data set is\n",
    "collected from https://aiyprojects.withgoogle.com/open_speech_recording, please\n",
    "consider contributing to help improve this and other models!\n",
    "\n",
    "As training progresses, it will print out its accuracy metrics, which should\n",
    "rise above 90% by the end. Once it's complete, you can run the freeze script to\n",
    "get a binary GraphDef that you can easily deploy on mobile applications.\n",
    "\n",
    "If you want to train on your own data, you'll need to create .wavs with your\n",
    "recordings, all at a consistent length, and then arrange them into subfolders\n",
    "organized by label. For example, here's a possible file structure:\n",
    "\n",
    "my_wavs >\n",
    "  up >\n",
    "    audio_0.wav\n",
    "    audio_1.wav\n",
    "  down >\n",
    "    audio_2.wav\n",
    "    audio_3.wav\n",
    "  other>\n",
    "    audio_4.wav\n",
    "    audio_5.wav\n",
    "\n",
    "You'll also need to tell the script what labels to look for, using the\n",
    "`--wanted_words` argument. In this case, 'up,down' might be what you want, and\n",
    "the audio in the 'other' folder would be used to train an 'unknown' category.\n",
    "\n",
    "To pull this all together, you'd run:\n",
    "\n",
    "bazel run tensorflow/examples/speech_commands:train -- \\\n",
    "--data_dir=my_wavs --wanted_words=up,down\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data\n",
    "#from home.pi.tensorflow.tensorflow_master.tensorflow.examples.speech_commands import input_data\n",
    "#/home/pi/tensorflow/tensorflow_master/tensorflow/examples/speech_commands\n",
    "\n",
    "import models\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  # Set the verbosity based on flags (default is INFO, so we see all messages)\n",
    "  tf.compat.v1.logging.set_verbosity(FLAGS.verbosity)\n",
    "\n",
    "  # Start a new TensorFlow session.\n",
    "  sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "  # Begin by making sure we have the training data we need. If you already have\n",
    "  # training data of your own, use `--data_url= ` on the command line to avoid\n",
    "  # downloading.\n",
    "  model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.feature_bin_count, FLAGS.preprocess)\n",
    "  audio_processor = input_data.AudioProcessor(\n",
    "      FLAGS.data_url, FLAGS.data_dir,\n",
    "      FLAGS.silence_percentage, FLAGS.unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings, FLAGS.summaries_dir)\n",
    "  fingerprint_size = model_settings['fingerprint_size']\n",
    "  label_count = model_settings['label_count']\n",
    "  time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)\n",
    "  # Figure out the learning rates for each training phase. Since it's often\n",
    "  # effective to have high learning rates at the start of training, followed by\n",
    "  # lower levels towards the end, the number of steps and learning rates can be\n",
    "  # specified as comma-separated lists to define the rate at each stage. For\n",
    "  # example --how_many_training_steps=10000,3000 --learning_rate=0.001,0.0001\n",
    "  # will run 13,000 training loops in total, with a rate of 0.001 for the first\n",
    "  # 10,000, and 0.0001 for the final 3,000.\n",
    "  training_steps_list = list(map(int, FLAGS.how_many_training_steps.split(',')))\n",
    "  learning_rates_list = list(map(float, FLAGS.learning_rate.split(',')))\n",
    "  if len(training_steps_list) != len(learning_rates_list):\n",
    "    raise Exception(\n",
    "        '--how_many_training_steps and --learning_rate must be equal length '\n",
    "        'lists, but are %d and %d long instead' % (len(training_steps_list),\n",
    "                                                   len(learning_rates_list)))\n",
    "\n",
    "  input_placeholder = tf.compat.v1.placeholder(\n",
    "      tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "  if FLAGS.quantize:\n",
    "    fingerprint_min, fingerprint_max = input_data.get_features_range(\n",
    "        model_settings)\n",
    "    fingerprint_input = tf.quantization.fake_quant_with_min_max_args(\n",
    "        input_placeholder, fingerprint_min, fingerprint_max)\n",
    "  else:\n",
    "    fingerprint_input = input_placeholder\n",
    "\n",
    "  logits, dropout_prob = models.create_model(\n",
    "      fingerprint_input,\n",
    "      model_settings,\n",
    "      FLAGS.model_architecture,\n",
    "      is_training=True)\n",
    "\n",
    "  # Define loss and optimizer\n",
    "  ground_truth_input = tf.compat.v1.placeholder(\n",
    "      tf.int64, [None], name='groundtruth_input')\n",
    "\n",
    "  # Optionally we can add runtime checks to spot when NaNs or other symptoms of\n",
    "  # numerical errors start occurring during training.\n",
    "  control_dependencies = []\n",
    "  if FLAGS.check_nans:\n",
    "    checks = tf.compat.v1.add_check_numerics_ops()\n",
    "    control_dependencies = [checks]\n",
    "\n",
    "  # Create the back propagation and training evaluation machinery in the graph.\n",
    "  with tf.compat.v1.name_scope('cross_entropy'):\n",
    "    cross_entropy_mean = tf.compat.v1.losses.sparse_softmax_cross_entropy(\n",
    "        labels=ground_truth_input, logits=logits)\n",
    "  if FLAGS.quantize:\n",
    "    tf.contrib.quantize.create_training_graph(quant_delay=0)\n",
    "  with tf.compat.v1.name_scope('train'), tf.control_dependencies(\n",
    "      control_dependencies):\n",
    "    learning_rate_input = tf.compat.v1.placeholder(\n",
    "        tf.float32, [], name='learning_rate_input')\n",
    "    train_step = tf.compat.v1.train.GradientDescentOptimizer(\n",
    "        learning_rate_input).minimize(cross_entropy_mean)\n",
    "  predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "  correct_prediction = tf.equal(predicted_indices, ground_truth_input)\n",
    "  confusion_matrix = tf.math.confusion_matrix(labels=ground_truth_input,\n",
    "                                              predictions=predicted_indices,\n",
    "                                              num_classes=label_count)\n",
    "  evaluation_step = tf.reduce_mean(input_tensor=tf.cast(correct_prediction,\n",
    "                                                        tf.float32))\n",
    "  with tf.compat.v1.get_default_graph().name_scope('eval'):\n",
    "    tf.compat.v1.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "    tf.compat.v1.summary.scalar('accuracy', evaluation_step)\n",
    "\n",
    "  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "  increment_global_step = tf.compat.v1.assign(global_step, global_step + 1)\n",
    "\n",
    "  saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables())\n",
    "\n",
    "  # Merge all the summaries and write them out to /tmp/retrain_logs (by default)\n",
    "  merged_summaries = tf.compat.v1.summary.merge_all(scope='eval')\n",
    "  train_writer = tf.compat.v1.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                                 sess.graph)\n",
    "  validation_writer = tf.compat.v1.summary.FileWriter(\n",
    "      FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "  tf.compat.v1.global_variables_initializer().run()\n",
    "\n",
    "  start_step = 1\n",
    "\n",
    "  if FLAGS.start_checkpoint:\n",
    "    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\n",
    "    start_step = global_step.eval(session=sess)\n",
    "\n",
    "  tf.compat.v1.logging.info('Training from step: %d ', start_step)\n",
    "\n",
    "  # Save graph.pbtxt.\n",
    "  tf.io.write_graph(sess.graph_def, FLAGS.train_dir,\n",
    "                    FLAGS.model_architecture + '.pbtxt')\n",
    "\n",
    "  # Save list of words.\n",
    "  with gfile.GFile(\n",
    "      os.path.join(FLAGS.train_dir, FLAGS.model_architecture + '_labels.txt'),\n",
    "      'w') as f:\n",
    "    f.write('\\n'.join(audio_processor.words_list))\n",
    "\n",
    "  # Training loop.\n",
    "  training_steps_max = np.sum(training_steps_list)\n",
    "  for training_step in xrange(start_step, training_steps_max + 1):\n",
    "    # Figure out what the current learning rate is.\n",
    "    training_steps_sum = 0\n",
    "    for i in range(len(training_steps_list)):\n",
    "      training_steps_sum += training_steps_list[i]\n",
    "      if training_step <= training_steps_sum:\n",
    "        learning_rate_value = learning_rates_list[i]\n",
    "        break\n",
    "    # Pull the audio samples we'll use for training.\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, 0, model_settings, FLAGS.background_frequency,\n",
    "        FLAGS.background_volume, time_shift_samples, 'training', sess)\n",
    "    # Run the graph with this batch of training data.\n",
    "    train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run(\n",
    "        [\n",
    "            merged_summaries,\n",
    "            evaluation_step,\n",
    "            cross_entropy_mean,\n",
    "            train_step,\n",
    "            increment_global_step,\n",
    "        ],\n",
    "        feed_dict={\n",
    "            fingerprint_input: train_fingerprints,\n",
    "            ground_truth_input: train_ground_truth,\n",
    "            learning_rate_input: learning_rate_value,\n",
    "            dropout_prob: 0.5\n",
    "        })\n",
    "    train_writer.add_summary(train_summary, training_step)\n",
    "    tf.compat.v1.logging.info(\n",
    "        'Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
    "        (training_step, learning_rate_value, train_accuracy * 100,\n",
    "         cross_entropy_value))\n",
    "    is_last_step = (training_step == training_steps_max)\n",
    "    if (training_step % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "      set_size = audio_processor.set_size('validation')\n",
    "      total_accuracy = 0\n",
    "      total_conf_matrix = None\n",
    "      for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "        validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(FLAGS.batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy, conf_matrix = sess.run(\n",
    "            [merged_summaries, evaluation_step, confusion_matrix],\n",
    "            feed_dict={\n",
    "                fingerprint_input: validation_fingerprints,\n",
    "                ground_truth_input: validation_ground_truth,\n",
    "                dropout_prob: 1.0\n",
    "            })\n",
    "        validation_writer.add_summary(validation_summary, training_step)\n",
    "        batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "        total_accuracy += (validation_accuracy * batch_size) / set_size\n",
    "        if total_conf_matrix is None:\n",
    "          total_conf_matrix = conf_matrix\n",
    "        else:\n",
    "          total_conf_matrix += conf_matrix\n",
    "      tf.compat.v1.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "      tf.compat.v1.logging.info('Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                                (training_step, total_accuracy * 100, set_size))\n",
    "\n",
    "    # Save the model checkpoint periodically.\n",
    "    if (training_step % FLAGS.save_step_interval == 0 or\n",
    "        training_step == training_steps_max):\n",
    "      checkpoint_path = os.path.join(FLAGS.train_dir,\n",
    "                                     FLAGS.model_architecture + '.ckpt')\n",
    "      tf.compat.v1.logging.info('Saving to \"%s-%d\"', checkpoint_path,\n",
    "                                training_step)\n",
    "      saver.save(sess, checkpoint_path, global_step=training_step)\n",
    "\n",
    "  set_size = audio_processor.set_size('testing')\n",
    "  tf.compat.v1.logging.info('set_size=%d', set_size)\n",
    "  total_accuracy = 0\n",
    "  total_conf_matrix = None\n",
    "  for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "    test_fingerprints, test_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, i, model_settings, 0.0, 0.0, 0, 'testing', sess)\n",
    "    test_accuracy, conf_matrix = sess.run(\n",
    "        [evaluation_step, confusion_matrix],\n",
    "        feed_dict={\n",
    "            fingerprint_input: test_fingerprints,\n",
    "            ground_truth_input: test_ground_truth,\n",
    "            dropout_prob: 1.0\n",
    "        })\n",
    "    batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "    total_accuracy += (test_accuracy * batch_size) / set_size\n",
    "    if total_conf_matrix is None:\n",
    "      total_conf_matrix = conf_matrix\n",
    "    else:\n",
    "      total_conf_matrix += conf_matrix\n",
    "  tf.compat.v1.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "  tf.compat.v1.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                            (total_accuracy * 100, set_size))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--data_url',\n",
    "      type=str,\n",
    "      # pylint: disable=line-too-long\n",
    "      default='https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz',\n",
    "      # pylint: enable=line-too-long\n",
    "      help='Location of speech training data archive on the web.')\n",
    "  parser.add_argument(\n",
    "      '--data_dir',\n",
    "      type=str,\n",
    "      default='/media/tegwyn/Xavier_SD/TensorFlow_speech_backups/speech_dataset/',\n",
    "      help=\"\"\"\\\n",
    "      Where to download the speech training data to.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--background_volume',\n",
    "      type=float,\n",
    "      default=0.1,\n",
    "      help=\"\"\"\\\n",
    "      How loud the background noise should be, between 0 and 1.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--background_frequency',\n",
    "      type=float,\n",
    "      default=0.8,\n",
    "      help=\"\"\"\\\n",
    "      How many of the training samples have background noise mixed in.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--silence_percentage',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help=\"\"\"\\\n",
    "      How much of the training data should be silence.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--unknown_percentage',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help=\"\"\"\\\n",
    "      How much of the training data should be unknown words.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--time_shift_ms',\n",
    "      type=float,\n",
    "      default=100.0,\n",
    "      help=\"\"\"\\\n",
    "      Range to randomly shift the training audio by in time.\n",
    "      \"\"\")\n",
    "  parser.add_argument(\n",
    "      '--testing_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of wavs to use as a test set.')\n",
    "  parser.add_argument(\n",
    "      '--validation_percentage',\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='What percentage of wavs to use as a validation set.')\n",
    "  parser.add_argument(\n",
    "      '--sample_rate',\n",
    "      type=int,\n",
    "      default=16000,\n",
    "      help='Expected sample rate of the wavs',)\n",
    "  parser.add_argument(\n",
    "      '--clip_duration_ms',\n",
    "      type=int,\n",
    "      default=1000,\n",
    "      help='Expected duration in milliseconds of the wavs',)\n",
    "  parser.add_argument(\n",
    "      '--window_size_ms',\n",
    "      type=float,\n",
    "      default=30.0,\n",
    "      help='How long each spectrogram timeslice is.',)\n",
    "  parser.add_argument(\n",
    "      '--window_stride_ms',\n",
    "      type=float,\n",
    "      default=10.0,\n",
    "      help='How far to move in time between spectogram timeslices.',)\n",
    "  parser.add_argument(\n",
    "      '--feature_bin_count',\n",
    "      type=int,\n",
    "      default=40,\n",
    "      help='How many bins to use for the MFCC fingerprint',\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--how_many_training_steps',\n",
    "      type=str,\n",
    "      default='15000,3000',\n",
    "      help='How many training loops to run',)\n",
    "  parser.add_argument(\n",
    "      '--eval_step_interval',\n",
    "      type=int,\n",
    "      default=400,\n",
    "      help='How often to evaluate the training results.')\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      type=str,\n",
    "      default='0.001,0.0001',\n",
    "      help='How large a learning rate to use when training.')\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type=int,\n",
    "      default=200,\n",
    "      help='How many items to train with at once',)\n",
    "  parser.add_argument(\n",
    "      '--summaries_dir',\n",
    "      type=str,\n",
    "      default='/tmp/retrain_logs',\n",
    "      help='Where to save summary logs for TensorBoard.')\n",
    "  parser.add_argument(\n",
    "      '--wanted_words',\n",
    "      type=str,\n",
    "      default='yes,no,up,down,left,right,on,off,stop,go',\n",
    "      help='Words to use (others will be added to an unknown label)',)\n",
    "  parser.add_argument(\n",
    "      '--train_dir',\n",
    "      type=str,\n",
    "      default='/tmp/speech_commands_train',\n",
    "      help='Directory to write event logs and checkpoint.')\n",
    "  parser.add_argument(\n",
    "      '--save_step_interval',\n",
    "      type=int,\n",
    "      default=100,\n",
    "      help='Save model checkpoint every save_steps.')\n",
    "  parser.add_argument(\n",
    "      '--start_checkpoint',\n",
    "      type=str,\n",
    "      default='',\n",
    "      help='If specified, restore this pretrained model before any training.')\n",
    "  parser.add_argument(\n",
    "      '--model_architecture',\n",
    "      type=str,\n",
    "      default='conv',\n",
    "      help='What model architecture to use')\n",
    "  parser.add_argument(\n",
    "      '--check_nans',\n",
    "      type=bool,\n",
    "      default=False,\n",
    "      help='Whether to check for invalid numbers during processing')\n",
    "  parser.add_argument(\n",
    "      '--quantize',\n",
    "      type=bool,\n",
    "      default=False,\n",
    "      help='Whether to train the model for eight-bit deployment')\n",
    "  parser.add_argument(\n",
    "      '--preprocess',\n",
    "      type=str,\n",
    "      default='mfcc',\n",
    "      help='Spectrogram processing mode. Can be \"mfcc\", \"average\", or \"micro\"')\n",
    "\n",
    "  # Function used to parse --verbosity argument\n",
    "  def verbosity_arg(value):\n",
    "    \"\"\"Parses verbosity argument.\n",
    "\n",
    "    Args:\n",
    "      value: A member of tf.logging.\n",
    "    Raises:\n",
    "      ArgumentTypeError: Not an expected value.\n",
    "    \"\"\"\n",
    "    value = value.upper()\n",
    "    if value == 'INFO':\n",
    "      return tf.compat.v1.logging.INFO\n",
    "    elif value == 'DEBUG':\n",
    "      return tf.compat.v1.logging.DEBUG\n",
    "    elif value == 'ERROR':\n",
    "      return tf.compat.v1.logging.ERROR\n",
    "    elif value == 'FATAL':\n",
    "      return tf.compat.v1.logging.FATAL\n",
    "    elif value == 'WARN':\n",
    "      return tf.compat.v1.logging.WARN\n",
    "    else:\n",
    "      raise argparse.ArgumentTypeError('Not an expected value')\n",
    "  parser.add_argument(\n",
    "      '--verbosity',\n",
    "      type=verbosity_arg,\n",
    "      default=tf.compat.v1.logging.INFO,\n",
    "      help='Log verbosity. Can be \"INFO\", \"DEBUG\", \"ERROR\", \"FATAL\", or \"WARN\"')\n",
    "\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
